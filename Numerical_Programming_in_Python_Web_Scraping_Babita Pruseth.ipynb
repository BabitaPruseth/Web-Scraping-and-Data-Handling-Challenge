{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKFlk3slQ1ol"
      },
      "source": [
        "# **Web Scraping & Data Handling Challenge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Contributer**- Babita Pruseth, Cohort Moscow, AlmaBetter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU_opgaCYpcO"
      },
      "source": [
        "\n",
        "\n",
        "### **Website:**\n",
        "JustWatch -  https://www.justwatch.com/in/movies?release_year_from=2000\n",
        "\n",
        "\n",
        "### **Description:**\n",
        "\n",
        "JustWatch is a popular platform that allows users to search for movies and TV shows across multiple streaming services like Netflix, Amazon Prime, Hulu, etc. For this assignment, you will be required to scrape movie and TV show data from JustWatch using Selenium, Python, and BeautifulSoup. Extract data from HTML, not by directly calling their APIs. Then, perform data filtering and analysis using Pandas, and finally, save the results to a CSV file.\n",
        "\n",
        "### **Tasks:**\n",
        "\n",
        "**1. Web Scraping:**\n",
        "\n",
        "Use BeautifulSoup to scrape the following data from JustWatch:\n",
        "\n",
        "   **a. Movie Information:**\n",
        "\n",
        "      - Movie title\n",
        "      - Release year\n",
        "      - Genre\n",
        "      - IMDb rating\n",
        "      - Streaming services available (Netflix, Amazon Prime, Hulu, etc.)\n",
        "      - URL to the movie page on JustWatch\n",
        "\n",
        "   **b. TV Show Information:**\n",
        "\n",
        "      - TV show title\n",
        "      - Release year\n",
        "      - Genre\n",
        "      - IMDb rating\n",
        "      - Streaming services available (Netflix, Amazon Prime, Hulu, etc.)\n",
        "      - URL to the TV show page on JustWatch\n",
        "\n",
        "  **c. Scope:**\n",
        "\n",
        "```\n",
        " ` - Scrape data for at least 50 movies and 50 TV shows.\n",
        "   - You can choose the entry point (e.g., starting with popular movies,\n",
        "     or a specific genre, etc.) to ensure a diverse dataset.`\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "**2. Data Filtering & Analysis:**\n",
        "\n",
        "   After scraping the data, use Pandas to perform the following tasks:\n",
        "\n",
        "   **a. Filter movies and TV shows based on specific criteria:**\n",
        "\n",
        "   ```\n",
        "      - Only include movies and TV shows released in the last 2 years (from the current date).\n",
        "      - Only include movies and TV shows with an IMDb rating of 7 or higher.\n",
        "```\n",
        "\n",
        "   **b. Data Analysis:**\n",
        "\n",
        "   ```\n",
        "      - Calculate the average IMDb rating for the scraped movies and TV shows.\n",
        "      - Identify the top 5 genres that have the highest number of available movies and TV shows.\n",
        "      - Determine the streaming service with the most significant number of offerings.\n",
        "      \n",
        "   ```   \n",
        "\n",
        "**3. Data Export:**\n",
        "\n",
        "```\n",
        "   - Dump the filtered and analysed data into a CSV file for further processing and reporting.\n",
        "\n",
        "   - Keep the CSV file in your Drive Folder and Share the Drive link on the colab while keeping view access with anyone.\n",
        "```\n",
        "\n",
        "**Submission:**\n",
        "```\n",
        "- Submit a link to your Colab made for the assignment.\n",
        "\n",
        "- The Colab should contain your Python script (.py format only) with clear\n",
        "  comments explaining the scraping, filtering, and analysis process.\n",
        "\n",
        "- Your Code shouldn't have any errors and should be executable at a one go.\n",
        "\n",
        "- Before Conclusion, Keep your Dataset Drive Link in the Notebook.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Note:**\n",
        "\n",
        "1. Properly handle errors and exceptions during web scraping to ensure a robust script.\n",
        "\n",
        "2. Make sure your code is well-structured, easy to understand, and follows Python best practices.\n",
        "\n",
        "3. The assignment will be evaluated based on the correctness of the scraped data, accuracy of data filtering and analysis, and the overall quality of the Python code.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ptoMlNQ5zB"
      },
      "source": [
        "# **Start The Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xHLaFLPn4yC"
      },
      "source": [
        "## **Task 1:- Web Scrapping**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axiEsy9ZL3qd",
        "outputId": "b3aca5ae-a23a-4f19-dddd-90cf340ee90e"
      },
      "outputs": [],
      "source": [
        "#Installing all necessary labraries\n",
        "!pip install bs4\n",
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "omJlLZASQBmU"
      },
      "outputs": [],
      "source": [
        "#import all necessary labraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCWbwB1Og3bD"
      },
      "source": [
        "## **Scrapping Movies Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPDgza5mQJKr",
        "outputId": "5429667a-9f38-4f54-f2c2-462369990f80"
      },
      "outputs": [],
      "source": [
        "def fetch_movie_urls(url):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        return \"Failed to retrieve the page, status code:\", response.status_code\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "\n",
        "url = 'https://www.justwatch.com/in/movies?release_year_from=2000'\n",
        "soup=fetch_movie_urls(url)\n",
        "print(soup.prettify())\n",
        "\n",
        "## Hint : Use the following code to extract the film urls\n",
        "# movie_links = soup.find_all('a', href=True)\n",
        "# movie_urls = [link['href'] for link in movie_links if '/movie/' in link['href']]\n",
        "\n",
        "# url_list=[]\n",
        "# for x in movie_urls:\n",
        "#   url_list.append('https://www.justwatch.com'+x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dam_ehZgvgmw"
      },
      "source": [
        "## **Scrapping Movie Title**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Movie title\n",
        "\n",
        "movie_title_list=[]# List to store all movie title\n",
        "\n",
        "# Extracting all movie titles from <a> tag and storing them in movie_titles\n",
        "movie_titles = soup.find_all('a',class_='title-list-grid__item--link',attrs={'href':True})\n",
        "\n",
        "# Extracting each movie title from movie_titles and storing in movie_title_list\n",
        "for movie_title in movie_titles:\n",
        "\n",
        "    # Extract the 'href' attribute value, which contains the movie title\n",
        "    data_id_value = movie_title['href']\n",
        "\n",
        "    # Removing the '/in/movie/' prefix to get the clean movie title\n",
        "    data_id_value = data_id_value.replace(\"/in/movie/\",\"\")\n",
        "\n",
        "    # Converting the movie title to uppercase and appending to the list\n",
        "    movie_title_list.append(data_id_value.upper())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-qsNrtIsBEp"
      },
      "source": [
        "## **Fetching Movie URL's**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nXj9U4lshQY1"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "# Movie url\n",
        "\n",
        "movie_url_list=[] # List to store all movie urls\n",
        "\n",
        "# For every movie title present in movies_title_list , Finding their url\n",
        "for movie in movie_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    movie_url_list.append(absolute_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List to store all movie URLs\n",
        "movie_url_list = []\n",
        "\n",
        "# For every movie title present in movies_title_list, finding their URL\n",
        "for movie in movie_title_list:\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    # Append the URL to the movie_url_list\n",
        "    movie_url_list.append(absolute_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEg1U1uPzGoj"
      },
      "source": [
        "## **Scrapping release Year**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "movie_release_year_list = []  # List to store all movie release years\n",
        "\n",
        "# For every movie title present in movie_title_list, find their release year\n",
        "for movie in movie_title_list:\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "\n",
        "    # Sending an HTTP GET request\n",
        "    response_ry = requests.get(absolute_url)\n",
        "\n",
        "    # Parsing HTML content with Beautiful Soup\n",
        "    soup_ry = BeautifulSoup(response_ry.text, 'html.parser')\n",
        "\n",
        "    # Finding the movie release year element\n",
        "    release_year_element = soup_ry.find('span', class_='text-muted')\n",
        "    \n",
        "    # Check if the element is found and handle None case\n",
        "    if release_year_element:\n",
        "        movie_release_year = release_year_element.text.strip()\n",
        "        movie_release_year = movie_release_year.replace(\"(\", \"\").replace(\")\", \"\")\n",
        "        movie_release_year_list.append(movie_release_year)\n",
        "    else:\n",
        "        # If the release year is not found, handle the missing case\n",
        "        movie_release_year_list.append('Year not found')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqzhL8STqaMX"
      },
      "source": [
        "## **Scrapping Genres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NYGVsfKjrDWr"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "# Movie genre\n",
        "\n",
        "movie_genre_list = []# List to store all movie genre\n",
        "\n",
        "# For every movie title present in movies_title_list , Finding their genre\n",
        "for movie in movie_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    response_g = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response_g.text,'html.parser')\n",
        "\n",
        "    # Selecting only those h3 whose heading is genres\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Genres')\n",
        "\n",
        "    if h3_element:\n",
        "        # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "        div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "        if div_element:\n",
        "            movie_genre_list.append(div_element.text.strip())\n",
        "        else:\n",
        "            movie_genre_list.append(\"Genre Not Listed\")\n",
        "    else:\n",
        "         movie_genre_list.append(\"Genre Not Listed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOof6-0xFuf6"
      },
      "source": [
        "## **Scrapping IMBD Rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gW467MLx6aCH"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "movie_imdb_list = []  # List to store all movie IMDb ratings\n",
        "\n",
        "# For every movie title present in movie_title_list, find their IMDb rating\n",
        "for movie in movie_title_list:\n",
        "    \n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    response_g = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response_g.text, 'html.parser')\n",
        "\n",
        "    # Selecting the h3 element whose heading is \"Rating\"\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Rating')\n",
        "\n",
        "    if not h3_element:\n",
        "        movie_imdb_list.append(\"IMDb Rating Not Listed.\")\n",
        "        continue  # Move to the next movie if the h3 element isn't found\n",
        "\n",
        "    # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "    div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "    if not div_element:\n",
        "        movie_imdb_list.append(\"IMDb Rating Not Listed.\")\n",
        "        continue  # Move to the next movie if div_element isn't found\n",
        "\n",
        "    # Find all div elements that contain the rating\n",
        "    rating_divs = div_element.find_all('div', class_='jw-scoring-listing__rating')\n",
        "\n",
        "    if not rating_divs:\n",
        "        movie_imdb_list.append(\"IMDb Rating Not Listed.\")\n",
        "        continue  # Move to the next movie if no rating divs are found\n",
        "\n",
        "    # Extract the last rating div as it contains the IMDb rating\n",
        "    last_rating_div = rating_divs[-1]\n",
        "    span_elements = last_rating_div.find_all('span')\n",
        "\n",
        "    if not span_elements:\n",
        "        movie_imdb_list.append(\"IMDb Rating Not Listed.\")\n",
        "        continue  # Move to the next movie if no span elements are found\n",
        "\n",
        "    # Extract the rating from the last span element\n",
        "    imdb_rating = span_elements[-1].text.strip()\n",
        "    movie_imdb_list.append(imdb_rating)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CHiu0A5RAuM"
      },
      "source": [
        "## **Scrapping Runtime/Duration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "movie_runtime_list = []  # List to store all movie runtimes/durations\n",
        "\n",
        "# For every movie title present in movie_title_list, find their Runtime/Duration\n",
        "for movie in movie_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    response_g = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response_g.text, 'html.parser')\n",
        "\n",
        "    # Selecting the h3 element whose heading is \"Runtime\"\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Runtime')\n",
        "\n",
        "    if not h3_element:\n",
        "        movie_runtime_list.append(\"No Runtime/Duration mentioned\")\n",
        "        continue  # Move to the next movie if the h3 element isn't found\n",
        "\n",
        "    # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "    div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "    if not div_element:\n",
        "        movie_runtime_list.append(\"No Runtime/Duration mentioned\")\n",
        "        continue  # Move to the next movie if div_element isn't found\n",
        "\n",
        "    # Extract and append the runtime text after stripping any extra spaces\n",
        "    movie_runtime_list.append(div_element.text.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edb4gsNcRJQN"
      },
      "source": [
        "## **Scrapping Age Rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZsHskhOcNAUj"
      },
      "outputs": [],
      "source": [
        "movie_age_rating_list = []  # List to store all movie age ratings\n",
        "\n",
        "# For every movie title present in movie_title_list, find their Age Rating\n",
        "for movie in movie_title_list:\n",
        "\n",
        "    # Construct the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    response_g = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response_g.text, 'html.parser')\n",
        "\n",
        "    # Find the h3 element with the heading 'Age rating'\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Age rating')\n",
        "\n",
        "    if not h3_element:\n",
        "        movie_age_rating_list.append(\"Age Rating Not Listed.\")\n",
        "        continue  # Move to the next movie if 'Age rating' isn't found\n",
        "\n",
        "    # Find the next sibling div that contains the age rating value\n",
        "    div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "    if not div_element:\n",
        "        movie_age_rating_list.append(\"Age Rating Not Listed.\")\n",
        "        continue  # Move to the next movie if no div with the age rating is found\n",
        "\n",
        "    # Append the age rating after stripping any extra spaces\n",
        "    movie_age_rating_list.append(div_element.text.strip())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RI5FD3CqFVV"
      },
      "source": [
        "## **Fetching Production Countries Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ai6YOgZmYIcc"
      },
      "outputs": [],
      "source": [
        "movie_production_country_list = []  # List to store all movie production countries\n",
        "\n",
        "# For every movie title present in movie_title_list, find their Production Country\n",
        "for movie in movie_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Selecting the h3 element with the subheading 'Production country'\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Production country')\n",
        "\n",
        "    if not h3_element:\n",
        "        movie_production_country_list.append(\"Production Country Not Listed\")\n",
        "        continue  # Move to the next movie if no 'Production country' heading is found\n",
        "\n",
        "    # Find the next sibling div that contains the production country value\n",
        "    div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "    if not div_element:\n",
        "        movie_production_country_list.append(\"Production Country Not Listed\")\n",
        "        continue  # Move to the next movie if no div with the production country is found\n",
        "\n",
        "    # Append the production country after stripping any extra spaces\n",
        "    movie_production_country_list.append(div_element.text.strip())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrJlIsBWrO2r"
      },
      "source": [
        "## **Fetching Streaming Service Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Yk72jDLZu7EZ"
      },
      "outputs": [],
      "source": [
        "movie_streaming_list = []  # List to store all movie streaming platforms\n",
        "\n",
        "# For every movie title present in movie_title_list, find their Streaming Platform\n",
        "for movie in movie_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each movie\n",
        "    absolute_url = 'https://www.justwatch.com/in/movie/' + movie\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Finding the outer div element with the class \"buybox-row stream\"\n",
        "    outer_div = soup.find('div', class_='buybox-row stream')\n",
        "\n",
        "    if not outer_div:\n",
        "        movie_streaming_list.append(\"Not Available for Streaming.\")\n",
        "        continue  # Move to the next movie if no streaming section is found\n",
        "\n",
        "    # Finding the nested div with class \"buybox-row__offers\"\n",
        "    inner_div = outer_div.find('div', class_='buybox-row__offers')\n",
        "\n",
        "    if not inner_div:\n",
        "        movie_streaming_list.append(\"Not Available for Streaming.\")\n",
        "        continue  # Move to the next movie if no offers section is found\n",
        "\n",
        "    # Find the picture element within the nested div\n",
        "    picture_element = inner_div.find('picture')\n",
        "\n",
        "    if not picture_element:\n",
        "        movie_streaming_list.append(\"Not Available for Streaming.\")\n",
        "        continue  # Move to the next movie if no picture element is found\n",
        "\n",
        "    # Extract the alt attribute from the img element inside the picture (contains the platform name)\n",
        "    img_element = picture_element.find('img')\n",
        "\n",
        "    if img_element and 'alt' in img_element.attrs:\n",
        "        movie_streaming_list.append(img_element['alt'])\n",
        "    else:\n",
        "        movie_streaming_list.append(\"Not Available for Streaming.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnh22VX_7f6K"
      },
      "source": [
        "## **Now Creating Movies DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7XQUICP5oBI"
      },
      "outputs": [],
      "source": [
        "# Creating Movies Dataframe\n",
        "\n",
        "data_movies = {\n",
        "    'Movie Title':movie_title_list,\n",
        "    'IMDB Rating':movie_imdb_list,\n",
        "    'Release Year':movie_release_year_list,\n",
        "    'Genre':movie_genre_list,\n",
        "    'Runtime/Duration':movie_runtime_list,\n",
        "    'Age Rating':movie_age_rating_list,\n",
        "    'Production Country':movie_production_country_list,\n",
        "    'Streaming Platform':movie_streaming_list,\n",
        "    'Url':movie_url_list\n",
        "}\n",
        "\n",
        "df_movies = pd.DataFrame(data_movies)\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(df_movies.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYQ5acWzJRZr"
      },
      "source": [
        "## **Scraping TV  Show Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xic8FWfwI6AT",
        "outputId": "3db52088-76b7-4412-897a-ef42eb69917c"
      },
      "outputs": [],
      "source": [
        "# Specifying the URL from which tv show related data will be fetched\n",
        "tv_url='https://www.justwatch.com/in/tv-shows?release_year_from=2000'\n",
        "# Sending an HTTP GET request to the URL\n",
        "page=requests.get(tv_url)\n",
        "# Parsing the HTML content using BeautifulSoup with the 'html.parser'\n",
        "soup=BeautifulSoup(page.text,'html.parser')\n",
        "# Printing the prettified HTML content\n",
        "print(soup.prettify())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vZLzmqcKDPX"
      },
      "source": [
        "## **Fetching Tv Show Title details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8Y6UF6-JLvO"
      },
      "outputs": [],
      "source": [
        "# Tv Shows title\n",
        "\n",
        "tv_show_title_list=[] # List to store all tv show title\n",
        "\n",
        "# Extracting all tv show titles and storing them in tv_show_titles\n",
        "tv_show_titles = soup_tv.find_all('a',class_='title-list-grid__item--link',attrs={'href':True})\n",
        "\n",
        "# Extracting each tv show title from tv_show_titles and storing in tv_show_title_list\n",
        "for tv_show_title in tv_show_titles:\n",
        "\n",
        "    # Extract the 'href' attribute value, which contains the tv_show title\n",
        "    data_id_value = tv_show_title['href']\n",
        "\n",
        "    # Removing the '/in/tv-show/' prefix to get the clean tv_show title\n",
        "    data_id_value = data_id_value.replace(\"/in/tv-show/\",\"\")\n",
        "\n",
        "    # Converting the tv_show title to uppercase and appending to the list\n",
        "    tv_show_title_list.append(data_id_value.upper())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Fetching Tv shows Url details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tv Shows url\n",
        "tv_show_url_list=[] # List to store all tv show urls\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their url\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "\n",
        "    tv_show_url_list.append(absolute_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEIt9j6RKa9B"
      },
      "source": [
        "## **Fetching Release Year**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r72fyiF8JozW"
      },
      "outputs": [],
      "source": [
        "# Tv Shows Release year\n",
        "\n",
        "# Movie release year\n",
        "tv_show_release_year_list = [] # List to store all tv show Release Year\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their release year\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "\n",
        "    # Sending an HTTP GET request to the url\n",
        "    response = requests.get(absolute_url)\n",
        "\n",
        "    # Parsing HTML content with Beautiful Soup\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "    tv_show_release_year =soup.find('span',class_='text-muted').text.strip()\n",
        "    tv_show_release_year=tv_show_release_year.replace(\"(\",\"\")\n",
        "    tv_show_release_year=tv_show_release_year.replace(\")\",\"\")\n",
        "    tv_show_release_year_list.append(tv_show_release_year)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P96pGO9kRCLv"
      },
      "source": [
        "## **Fetching TV Show Genre Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jay8a9xgT43-"
      },
      "outputs": [],
      "source": [
        "# Tv Shows Genre\n",
        "\n",
        "tv_show_genre_list = [] # List to store all tv show Genres\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their Genre\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "    # Selecting only those h3 whose heading is genres\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Genres')\n",
        "\n",
        "    if h3_element:\n",
        "        # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "        div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "        if div_element:\n",
        "            tv_show_genre_list.append(div_element.text.strip())\n",
        "        else:\n",
        "            tv_show_genre_list.append(\"Genre Not Listed\")\n",
        "    else:\n",
        "         tv_show_genre_list.append(\"Genre Not Listed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk3eSdDAXQv8"
      },
      "source": [
        "## **Fetching IMDB Rating Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmltFOQEXM2W"
      },
      "outputs": [],
      "source": [
        "# Tv Shows  Imdb Rating\n",
        "\n",
        "tv_show_imdb_list = [] # List to store all tv show Imdb Rating\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their Imdb Rating\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Selecting only those h3 whose heading is Rating\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Rating')\n",
        "\n",
        "    if h3_element:\n",
        "        # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "        div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "        if div_element:\n",
        "            inside_div = div_element.find_all('div', class_='jw-scoring-listing__rating')\n",
        "\n",
        "            # Check if inside_div is non-empty\n",
        "            if inside_div:\n",
        "                inside_div_last = inside_div[-1] # extracting last div of inside div as last div elemnt contains span (in which last span contains rating)\n",
        "\n",
        "                # Check if inside_div_last is non-empty\n",
        "                if inside_div_last:\n",
        "                    span_all = inside_div_last.find_all('span')\n",
        "\n",
        "                    # Check if span_all is non-empty\n",
        "                    if span_all:\n",
        "                        span_last = span_all[-1] # Here we are extracting rating from the last span(span_last) inside last div(inside_div_last) of main div_element(div_element)\n",
        "                        tv_show_imdb_list.append(span_last.text.strip())\n",
        "                    else:\n",
        "                        tv_show_imdb_list.append(\"Imdb Rating Not Listed.\")\n",
        "                else:\n",
        "                    tv_show_imdb_list.append(\"Imdb Rating Not Listed.\")\n",
        "            else:\n",
        "                tv_show_imdb_list.append(\"Imdb Rating Not Listed.\")\n",
        "        else:\n",
        "            tv_show_imdb_list.append(\"Imdb Rating Not Listed.\")\n",
        "    else:\n",
        "        tv_show_imdb_list.append(\"Imdb Rating Not Listed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ9nJhmiZB_W"
      },
      "source": [
        "## **Fetching Age Rating Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR9Xo8piZA7p"
      },
      "outputs": [],
      "source": [
        "# Tv Shows Age Rating\n",
        "\n",
        "tv_show_age_rating_list = [] # List to store all tv show Age Ratings\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their Age Rating\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "    # Selecting only those h3 whose heading is Age rating\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Age rating')\n",
        "\n",
        "    if h3_element:\n",
        "        # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "        div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "        if div_element:\n",
        "            tv_show_age_rating_list.append(div_element.text.strip())\n",
        "        else:\n",
        "            tv_show_age_rating_list.append(\"Age Rating Not Listed.\")\n",
        "    else:\n",
        "         tv_show_age_rating_list.append(\"Age Rating Not Listed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii49LH4tdNoN"
      },
      "source": [
        "## **Fetching Production Country details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xihOeyN8XXDt"
      },
      "outputs": [],
      "source": [
        "# Tv Shows Production Country\n",
        "\n",
        "tv_show_production_country_list=[] # List to store all tv show Production Countries\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their Production country\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "    # Selecting only those h3 whose sub-heading inside details- infos is 'Production Country'\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string=' Production country ')\n",
        "\n",
        "    if h3_element:\n",
        "        # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "        div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "        if div_element:\n",
        "            tv_show_production_country_list.append(div_element.text.strip())\n",
        "        else:\n",
        "            tv_show_production_country_list.append(\"Production Country Not Listed\")\n",
        "    else:\n",
        "          tv_show_production_country_list.append(\"Production Country Not Listed\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHZwwgiKdlQm"
      },
      "source": [
        "## **Fetching Streaming Service details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MBl6Vqadrl9"
      },
      "outputs": [],
      "source": [
        "# Tv Shows Streaming Platform\n",
        "\n",
        "tv_show_streaming_list=[] # List to store all tv show Streaming Platorms\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their Streaming Platform\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "    # Finding the outer div element with the class \"buybox-row stream\"\n",
        "    outer_div = soup.find('div', class_='buybox-row stream')\n",
        "\n",
        "    if outer_div:\n",
        "        # Finding the nested div with class \"buybox-row__offers\" inside the outer div\n",
        "        inner_div = outer_div.find('div', class_='buybox-row__offers')\n",
        "\n",
        "        if inner_div:\n",
        "            # Find the picture element within the nested div\n",
        "            picture_element = inner_div.find('picture')\n",
        "\n",
        "            if picture_element:\n",
        "                # Extract the alt attribute from the img element inside the picture which contains streaming platform name\n",
        "                img_element = picture_element.find('img')\n",
        "                if img_element:\n",
        "                    alt_text = img_element['alt']\n",
        "                    tv_show_streaming_list.append(alt_text)\n",
        "                else:\n",
        "                    tv_show_streaming_list.append(\"Not Available for Streaming.\")\n",
        "            else:\n",
        "                tv_show_streaming_list.append(\"Not Available for Streaming.\")\n",
        "        else:\n",
        "            tv_show_streaming_list.append(\"Not Available for Streaming.\")\n",
        "    else:\n",
        "        tv_show_streaming_list.append(\"Not Available for Streaming.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUOtDJv9gM4a"
      },
      "source": [
        "## **Fetching Duration Details**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4x4YY6AfoL1"
      },
      "outputs": [],
      "source": [
        "# Tv Shows Runtime/Duration\n",
        "\n",
        "tv_show_runtime_list=[] # List to store all tv show Runtimes\n",
        "\n",
        "# For every tv show title present in tv_show_title_list , Finding their Runtime/Duration\n",
        "for tv_show in tv_show_title_list:\n",
        "\n",
        "    # Constructing the absolute URL for fetching each tv show\n",
        "    absolute_url = 'https://www.justwatch.com/in/tv-show/' + tv_show\n",
        "    response = requests.get(absolute_url)\n",
        "    soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "    # Selecting only those h3 whose heading is runtine\n",
        "    h3_element = soup.find('h3', class_='detail-infos__subheading', string='Runtime')\n",
        "\n",
        "    if h3_element:\n",
        "        # Check if the next sibling is a div with class \"detail-infos__value\"\n",
        "        div_element = h3_element.find_next_sibling('div', class_='detail-infos__value')\n",
        "\n",
        "        if div_element:\n",
        "            tv_show_runtime_list.append(div_element.text.strip())\n",
        "        else:\n",
        "            tv_show_runtime_list.append(\"No Runtime/Duration mentioned\")\n",
        "    else:\n",
        "      tv_show_runtime_list.append(\"No Runtime/Duration mentioned\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD4QVPT-nfVR"
      },
      "source": [
        "## **Creating TV Show DataFrame**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Lnlb-xip2U"
      },
      "outputs": [],
      "source": [
        "# Write Your Code here\n",
        "# Creating Tv Shows Dataframe\n",
        "\n",
        "data_tv_shows = {\n",
        "    'Tv_Show Title':tv_show_title_list,\n",
        "    'IMDB Rating':tv_show_imdb_list,\n",
        "    'Release Year':tv_show_release_year_list,\n",
        "    'Genre':tv_show_genre_list,\n",
        "    'Runtime/Duration':tv_show_runtime_list,\n",
        "    'Age Rating':tv_show_age_rating_list,\n",
        "    'Production Country':tv_show_production_country_list,\n",
        "    'Streaming Platform':tv_show_streaming_list,\n",
        "    'Url':tv_show_url_list\n",
        "}\n",
        "\n",
        "df_tv_shows = pd.DataFrame(data_tv_shows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyqHHKh4IDx6"
      },
      "source": [
        "## **Task 2 :- Data Filtering & Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly64H04vH1v9"
      },
      "outputs": [],
      "source": [
        "# Filtering movies and TV shows to include only those released in the last two years and with an IMDB Rating of 7 or higher.\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Get the current date\n",
        "current_date = datetime.now()\n",
        "\n",
        "# Calculate the date 2 years ago from the current date\n",
        "two_years_ago = current_date - timedelta(days=365 * 2)\n",
        "\n",
        "def filter_df(df, release_year_col, imdb_rating_col, years_ago, current_date):\n",
        "    # Convert 'Release Year' to datetime format\n",
        "    df[release_year_col] = pd.to_datetime(df[release_year_col], errors='coerce')\n",
        "\n",
        "    # Filter the DataFrame to include only entries released in the last `years_ago` years\n",
        "    filtered_df = df[(df[release_year_col] >= two_years_ago) & (df[release_year_col] <= current_date)].copy()\n",
        "\n",
        "    # Converting 'IMDB Rating' column to a string so that, in the next step, we can convert it to numeric values\n",
        "    filtered_df.loc[:, imdb_rating_col] = filtered_df[imdb_rating_col].astype(str)\n",
        "\n",
        "    # Extract numeric part and convert to numeric\n",
        "    filtered_df[imdb_rating_col] = pd.to_numeric(filtered_df[imdb_rating_col].str.extract(r'([\\d.]+)', expand=False), errors='coerce')\n",
        "\n",
        "    # Filter the DataFrame to include only entries whose IMDb Rating >= 7\n",
        "    filtered_df = filtered_df[filtered_df[imdb_rating_col] >= 7]\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "# Filtering Movies\n",
        "filtered_df_movies = filter_df(df_movies, 'Release Year', 'IMDB Rating', two_years_ago, current_date)\n",
        "\n",
        "# Filtering TV Shows\n",
        "filtered_df_tv_shows = filter_df(df_tv_shows, 'Release Year', 'IMDB Rating', two_years_ago, current_date)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bPDbn-gPyfm"
      },
      "source": [
        "## **Calculating Mean IMDB Ratings for both Movies and Tv Shows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aGmGPOlIkk4"
      },
      "outputs": [],
      "source": [
        "# Calculating Movies mean IMDb rating\n",
        "movie_mean_imdb = filtered_df_movies['IMDB Rating'].mean()\n",
        "movie_mean_imdb_rounded = round(movie_mean_imdb, 2)\n",
        "print(\"Mean IMDb Rating for Movies is:\", movie_mean_imdb_rounded)\n",
        "\n",
        "# Calculating Tv Shows mean IMDb rating\n",
        "tv_mean_imdb = filtered_df_tv_shows['IMDB Rating'].mean()\n",
        "tv_mean_imdb_rounded = round(tv_mean_imdb, 2)\n",
        "print(\"Mean IMDb Rating for Tv Shows is:\", tv_mean_imdb_rounded)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_OroblUQG4r"
      },
      "source": [
        "## **Analyzing Top Genres**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ljPnIn2LJLZ"
      },
      "outputs": [],
      "source": [
        "# Function for Finding top 5 Highest Imdb rating movies / tv shows\n",
        "\n",
        "def get_top_5_imdb(df):\n",
        "\n",
        "  # Convert 'IMDB Rating' column to string\n",
        "  df['IMDB Rating'] = df['IMDB Rating'].astype(str)\n",
        "\n",
        "  # Extract only the IMDb rating value\n",
        "  df['IMDB Rating'] = df['IMDB Rating'].str.extract('(\\d+\\.\\d+)')\n",
        "\n",
        "  # Convert the 'IMDB Rating' column to numeric\n",
        "  df['IMDB Rating'] = pd.to_numeric(df['IMDB Rating'], errors='coerce')\n",
        "\n",
        "  # Select the top 5 movies/Tv Shows based on IMDb rating\n",
        "  top_5 = df.nlargest(5, 'IMDB Rating')\n",
        "\n",
        "  return top_5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nqu7MEEYa3c"
      },
      "outputs": [],
      "source": [
        "# Top 5 Highest IMDB Rating Movies\n",
        "\n",
        "top_5_movies = get_top_5_imdb(filtered_df_movies)\n",
        "print(top_5_movies.loc[:, ['Movie Title', 'IMDB Rating']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 5 Highest IMDB Rating Tv Shows\n",
        "\n",
        "top_5_tv_shows = get_top_5_imdb(filtered_df_tv_shows)\n",
        "print(top_5_tv_shows.loc[:, ['Tv_Show Title', 'IMDB Rating']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUPye0P0QP5I"
      },
      "source": [
        "## **Finding Predominant Streaming Service**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLXiCZSAO_40"
      },
      "outputs": [],
      "source": [
        "# Funtion for Finding  Movies / Tv Shows Predominant Streaming Service\n",
        "\n",
        "def visualize_streaming_distribution_wordcloud(df):\n",
        "    # Filter streaming information available\n",
        "    streaming_platforms = df[df['Streaming Platform'] != 'Not Available for Streaming.']['Streaming Platform']\n",
        "\n",
        "    # Create a string of streaming platforms\n",
        "    streaming_text = ' '.join(streaming_platforms)\n",
        "\n",
        "    # Generate the word cloud\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(streaming_text)\n",
        "\n",
        "    # Display the word cloud\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('Streaming Service Distribution - Word Cloud')\n",
        "    plt.show()\n",
        "\n",
        "    # Identify the predominant streaming service\n",
        "    predominant_service = streaming_platforms.mode().iloc[0]\n",
        "    print(f\"The predominant streaming service is: {predominant_service}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tytqsADVR2x6"
      },
      "source": [
        "## **Task 3 :- Data Export**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4yaUlvrRj6g"
      },
      "outputs": [],
      "source": [
        "# Saving Final Movies/Tv Shows dataframe as Final Data in csv format\n",
        "\n",
        "df_movies.to_csv('Final_Movies_Data.csv', index=False)\n",
        "df_tv_shows.to_csv('Final_Tv_Shows_Data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSmCEV22SSW_"
      },
      "outputs": [],
      "source": [
        "# Saving Filtered Movies/Tv Shows dataframe as Filtered Data in csv format\n",
        "\n",
        "filtered_df_movies.to_csv('Filtered_Movies_Data.csv', index=False)\n",
        "filtered_df_tv_shows.to_csv('Filtered_Tv_Shows_Data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s-10dFhWZf4"
      },
      "source": [
        "# ***Congratulations!!! You have completed your Assignment.***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bKFlk3slQ1ol",
        "V-qsNrtIsBEp",
        "Dam_ehZgvgmw",
        "VEg1U1uPzGoj",
        "aqzhL8STqaMX",
        "UOof6-0xFuf6",
        "8CHiu0A5RAuM",
        "edb4gsNcRJQN",
        "_RI5FD3CqFVV",
        "IrJlIsBWrO2r",
        "Mnh22VX_7f6K",
        "LYQ5acWzJRZr",
        "ev-VUSNvJ-fJ",
        "1vZLzmqcKDPX",
        "mEIt9j6RKa9B",
        "P96pGO9kRCLv",
        "hk3eSdDAXQv8",
        "XZ9nJhmiZB_W",
        "ii49LH4tdNoN",
        "mHZwwgiKdlQm",
        "uUOtDJv9gM4a",
        "nD4QVPT-nfVR",
        "CyqHHKh4IDx6",
        "0bPDbn-gPyfm",
        "N_OroblUQG4r",
        "BUPye0P0QP5I",
        "tytqsADVR2x6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
